# RLPlanner-MF
<P> As the complexity and compactness of 2.5D systems increase, floorplanning encounters challenges such as thermal-interconnect tradeoff, thermal computation, and efficiency. To address these issues, we present RLPlanner-MF, an advanced floorplanning tool for 2.5D systems. RLPlanner-MF incorporates FastTM, a novel thermal evaluation method that significantly accelerates computation, and a chiplet-ordering algorithm to optimize chiplet placement sequence. Leveraging reinforcement learning (RL), RLPlanner-MF jointly optimizes total wirelength and peak temperature. To enhance generalization across unseen designs, it adopts a multi-modal fusion approach, combining a Graph Convolutional Network (GCN) with a Convolutional Neural Network (CNN). Extensive experiments show that FastTM achieves a 120× speedup in thermal evaluations compared to Hotspot, while maintaining high accuracy. RLPlanner-MF delivers an average 20.33\% improvement in the target objective and provides a 2.7$\times$ speedup over state-of-the-art methods.
</P>

## Benchmarks
<img src="https://github.com/weiweihook/RLPlanner-MF/blob/main/benchmark.png" width="400"/>

## Hypeparameters
<center>
  
| Hyperparameter | Value |
| :-------------------------:|:-------------------------: |
| Activation Function | ReLU|
| Optimizer           | Adam |
| Learning Rate       | 2.5E-4 |
| Parallel environment (n_e)       | 64/128/256 |
| Batch Size          | n_e * len(episode) |
| Clip Gradient Norm  | 0.5 |
| Total Epoch         | 500 |
| Clipping Coefficient| 0.1 |
| Entropy Coefficient | 0.01|
| Value Coefficient   | 0.5 |
| Discount(γ)         | 0.99|
  
</center>

*The length of each episode depends on the number of chiplets.



## Configurations
We use .cfg file to describe a 2.5D system. Here we briefly describe the options in the .cfg file.
### [chiplets]
- **chiplet_count**: the number of chiplets in the 2.5D system.
- **widths**: the width of each chiplet, separated by ",".
- **heights**: the height of each chiplet, separated by ",".
- **powers**: the power of each chiplet, separated by ",".
- **connections**: the connection matrix of chiplets. The i-th row and j-th column in the matrix is the bandwidth from chiplet i to chiplet j.
- **u**: the graph node 'i'.
- **v**: the graph node 'j'.
- **e**: the connection wires between node 'i' and 'j'.

## Thermal Evaluations
<img src="https://github.com/weiweihook/RLPlanner-MF/blob/main/comparison.png" width="300"/>
Fig.1 Temperature predictions vs ground truths. The grey line represents the ground truths obtained from HotSpot, while the purple dots denote the temperature predictions from FastTM.


<img src="https://github.com/weiweihook/RLPlanner-MF/blob/main/thermal_map.png" width="400"/>
Fig.2 Thermal maps of the chiplet layer: (a) Hotspot; (b) FastTM; (c) ThermalGCN. Temperature difference (d) with Hotspot. Residual thermal maps between Hotspot: (e) FastTM; (f) ThermalGCN.


Figure 1 compares the temperatures predicted by FastTM against ground-truth values across approximately 4 million grid points. FastTM predictions closely match the ground truth, as indicated by the yellow reference line, and achieve a coefficient of determination (R2) of 0.9972. For further validation, we randomly selected a chiplet floorplan to contrast thermal profiles generated by different methods. Figure 2 reveals near-identical thermal distributions between FastTM and Hotspot, whereas Hotspot and ThermalGCN exhibit significant discrepancies.


## Floorplan Comparison

<img src="https://github.com/weiweihook/RLPlanner-MF/blob/main/thermal_map.png" width="400"/>
Fig.3. Floorplans and thermal maps of the Ascend910 system: (a)(d) RLPlanner-MF; (b)(e) TAP-2.5D; (c)(f) TAP-2.5D+FastTM.

Figure 3 illustrates the Ascend910 system floorplans and corresponding thermal maps generated by three distinct methods. As all temperatures remain below 80◦C, a high-quality floorplan prioritizes smaller wirelength, producing a more compact layout with reduced whitespace. Despite exhibiting the highest overall temperature distribution, RLPlanner-MF achieves the shortest wirelength among the three methods.

## Ablation Study

### Chiplet-ordering Impacts on performance
<P>An ablation experiment was conducted to explore the impact of the chiplet-ordering algorithm on performance. We compared the developed algorithm with a size-based sorting method that only considers chiplet sizes across various benchmarks. RLPlanner-MF using the chiplet-ordering algorithm achieves an average reward improvement of 7.18% over the size-based method. Notably, in specific cases such as Ascend910, Multi-GPU, syn5, and syn6, the chiplet-ordering algorithm produces sequences identical to those generated by the size-based method, yielding equivalent rewards. This demonstrates the efficacy of the chiplet-ordering algorithm in delivering superior performance and more nuanced optimization compared to the simpler size-based approach.</P>

<img src="https://github.com/weiweihook/RLPlanner-MF/blob/main/ablation_study/ablation_study1.png" width="400"/>

### GCN, RND and Dense Reward Impacts on Performance
<P>To evaluate the efficacy of the GCN, RND, and dense reward strategy within the RLPlanner-MF framework, we performed ablation studies on the DATE2021 benchmark. These studies compared three configurations: (i) a CNN encoder exclusively in RLPlanner-MF, (ii) the framework without RND, and (iii) the omission of dense rewards. The results of these configurations are presented in below Table, where "w/o. GCN", "w/o. RND", and "w/o. Dense Reward" denote the framework excluding the GCN, RND, and dense reward strategy, respectively. RLPlanner-MF incorporating all components, consistently produces superior floorplanning solutions, achieving rewards that exceed the ablated configurations by average margins of 5.38%, 2.57%, and 3.52% across the three benchmarks. The GCN enhances feature embedding efficiency by explicitly modeling topological relationships, addressing the limitations of CNN-based image embeddings that ignore structural connectivity. Similarly, the inclusion of RND improves exploration by incentivizing the agent to visit novel states through intrinsic rewards derived from the prediction error of an untrained neural network. This mechanism promotes the discovery of robust strategies in complex environments. Furthermore, the dense reward strategy accelerates learning by providing frequent, incremental feedback during training, enabling finer-grained policy adjustmentsand higher-quality solutions.</P>

<img src="https://github.com/weiweihook/RLPlanner-MF/blob/main/ablation_study/ablation_study2.png" width="400"/>

## References
[1]Y. Ma, L. Delshadtehrani, C. Demirkiran, J. L. Abellan, and A. Joshi, “Tap-2.5 d: A thermally-aware chiplet placement methodology for 2.5 d systems,” in 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE, 2021, pp. 1246–1251.

[2]“Mcnc benchmark.” [Online]. Available: https://s2.smu.edu/∼manikas/Benchmarks/MCNC Benchmark Netlists.html.
